{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc7a8f20-9e5e-4618-9504-4584ff026aeb",
   "metadata": {},
   "source": [
    "# Iterative updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1def9af1-123f-4b4e-9927-6dc12597a71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'employees_python' does not exist. Creating it now and uploading the data...\n",
      "Table 'employees_python' created and data uploaded.\n",
      "Total incremental updates (first run): 177 records inserted.\n",
      "Table 'timesheets_python' does not exist. Creating it now and uploading the data...\n",
      "Table 'timesheets_python' created and data uploaded.\n",
      "Total incremental updates (first run): 39714 records inserted.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "# Database connection parameters for PostgreSQL\n",
    "DB_USER = 'postgres'\n",
    "DB_PASSWORD = 'password'\n",
    "DB_HOST = 'db'\n",
    "DB_PORT = '5432'\n",
    "DB_NAME = 'mydatabase'\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "# Function to check if the table exists in the database\n",
    "def check_table_exists(engine, table_name):\n",
    "    query = text(f\"\"\"\n",
    "    SELECT EXISTS (\n",
    "        SELECT FROM information_schema.tables \n",
    "        WHERE table_name = '{table_name}'\n",
    "    );\n",
    "    \"\"\")\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query).scalar()\n",
    "    return result\n",
    "\n",
    "# Function to load CSV data\n",
    "def load_csv_data(csv_file_path):\n",
    "    new_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Handling specific cases (rename column as needed for the employee dataset)\n",
    "    if csv_file_path == 'data/employees.csv':\n",
    "        new_data.rename(columns={'employe_id': 'employee_id'}, inplace=True)\n",
    "\n",
    "    return new_data\n",
    "\n",
    "# Main function for incremental update\n",
    "def incremental_update(engine, csv_file_path, table_name, update_keys):\n",
    "    # Ensure update_keys is a list\n",
    "    if not isinstance(update_keys, list):\n",
    "        update_keys = [update_keys]\n",
    "\n",
    "    # Load the new data from the CSV file\n",
    "    new_data = load_csv_data(csv_file_path)\n",
    "\n",
    "    # First time: create the table and insert all data if the table doesn't exist\n",
    "    if not check_table_exists(engine, table_name):\n",
    "        print(f\"Table '{table_name}' does not exist. Creating it now and uploading the data...\")\n",
    "\n",
    "        # Create the table with the schema based on the CSV data\n",
    "        new_data.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "        print(f\"Table '{table_name}' created and data uploaded.\")\n",
    "\n",
    "        # Since this is the first run, the total incremental updates are all the rows in the new data\n",
    "        total_updates = len(new_data)\n",
    "        print(f\"Total incremental updates (first run): {total_updates} records inserted.\")\n",
    "    else:\n",
    "        print(f\"Table '{table_name}' exists. Performing incremental update...\")\n",
    "\n",
    "        # Load the existing data from the database\n",
    "        existing_data = pd.read_sql_table(table_name, con=engine)\n",
    "\n",
    "        # Ensure all update_keys exist in both datasets\n",
    "        for key in update_keys:\n",
    "            if key not in new_data.columns or key not in existing_data.columns:\n",
    "                raise KeyError(f\"Both the new data and existing data must have the '{key}' column for the incremental update.\")\n",
    "\n",
    "        # Merge the existing data with the new data based on the update_keys\n",
    "        # We update rows with the same update_keys and append new rows that don't exist\n",
    "        merged_data = pd.concat([existing_data, new_data]).drop_duplicates(subset=update_keys, keep='last')\n",
    "        # Count the number of new or updated records\n",
    "        updated_or_new_data = merged_data[~merged_data[update_keys].apply(tuple, 1).isin(existing_data[update_keys].apply(tuple, 1))]\n",
    "        total_updates = len(updated_or_new_data)\n",
    "\n",
    "        # Write the merged DataFrame back to the database (replace existing data)\n",
    "        updated_or_new_data.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "\n",
    "        print(f\"Incremental update completed successfully.\")\n",
    "        print(f\"Total incremental updates: {total_updates} records inserted or updated.\")\n",
    "\n",
    "\n",
    "csv_files = [\n",
    "    {'path': 'data/employees.csv', 'table': 'employees_python', 'keys': ['employee_id','branch_id']},\n",
    "    {'path': 'data/timesheets.csv', 'table': 'timesheets_python', 'keys': ['timesheet_id']}\n",
    "]\n",
    "\n",
    "for file in csv_files:\n",
    "    incremental_update(engine, file['path'], file['table'], file['keys'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e09813-172c-4dee-ac99-35601a5d6066",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6bfa3c-5136-4b0b-a279-cd9b32a1fd70",
   "metadata": {},
   "source": [
    "## Timesheets Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ad9a9-6f17-4e91-be1f-e51a6e63a3f9",
   "metadata": {},
   "source": [
    "- check is there any duplicate for timesheets tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b37fc42b-bb48-49b8-983a-23a2ee80f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   raw_timesheet_id  unique_timesheet_id\n",
      "0             39714                39714\n",
      "There is no duplicate data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "timesheets = pd.read_sql_table(\"timesheets_python\", con=engine)\n",
    "# Count the total number of timesheet_id\n",
    "raw_timesheet_id = timesheets['timesheet_id'].count()\n",
    "\n",
    "# Count the number of unique timesheet_id\n",
    "unique_timesheet_id = timesheets['timesheet_id'].nunique()\n",
    "\n",
    "# Display the results\n",
    "result = pd.DataFrame({\n",
    "    'raw_timesheet_id': [raw_timesheet_id],\n",
    "    'unique_timesheet_id': [unique_timesheet_id]\n",
    "})\n",
    "\n",
    "print(result)\n",
    "\n",
    "if raw_timesheet_id == unique_timesheet_id:\n",
    "    print(\"There is no duplicate data.\")\n",
    "else:\n",
    "    print(\"There are duplicates in the data.\")\n",
    "\n",
    "# answer: there is no duplicate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd08853-cb2a-4a80-be69-da9f40ed6420",
   "metadata": {},
   "source": [
    "- check is company implements two shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441505b6-c5da-45d4-9c80-ca715f8917b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/3040672674.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  timesheets['checkin'] = pd.to_datetime(timesheets['checkin'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          max_checkin         min_checkin\n",
      "0 2024-10-02 23:59:00 2024-10-02 00:00:14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the 'checkin' column to datetime if it's not already\n",
    "timesheets['checkin'] = pd.to_datetime(timesheets['checkin'], errors='coerce')\n",
    "\n",
    "# Calculate the maximum and minimum checkin times\n",
    "max_checkin = timesheets['checkin'].max()\n",
    "min_checkin = timesheets['checkin'].min()\n",
    "\n",
    "# Display the results\n",
    "result = pd.DataFrame({\n",
    "    'max_checkin': [max_checkin],\n",
    "    'min_checkin': [min_checkin]\n",
    "})\n",
    "\n",
    "print(result)\n",
    "\n",
    "# It seems the company implements two shifts, because the result of checkin time is 24 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3a4e9-be85-4083-93fa-9375c3d96949",
   "metadata": {},
   "source": [
    "- check is there any missing value for checkin or checkout column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318bd9f4-fe2c-449f-96fb-c2cee960c3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timesheet_id  employee_id        date             checkin  checkout\n",
      "3       23907435           63  2019-08-21 2024-10-02 09:55:47      None\n",
      "7       23907445           60  2019-08-22                 NaT  18:04:33\n",
      "16      23907459           31  2019-08-26                 NaT  17:57:45\n",
      "20      23907468           22  2019-08-27                 NaT  18:25:52\n",
      "21      23907470           21  2019-08-27                 NaT  18:35:22\n",
      "It seems there are missing values in checkin or checkout.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter for rows where checkin or checkout is null\n",
    "missing_values = timesheets[timesheets['checkin'].isnull() | timesheets['checkout'].isnull()]\n",
    "\n",
    "# Get the first 5 rows with missing values\n",
    "result = missing_values.head(5)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "# Answer: Check for missing values\n",
    "if not result.empty:\n",
    "    print(\"It seems there are missing values in checkin or checkout.\")\n",
    "else:\n",
    "    print(\"There are no missing values in checkin or checkout.\")\n",
    "\n",
    "# it seems there is missing value on checkin or checkout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ffd177-774f-4b39-a1a4-babd3932e71b",
   "metadata": {},
   "source": [
    "- check is there any missing value for both of column (checkin and checkout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a65fc2f7-91b0-47c6-a7b7-6dabf0f6894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [timesheet_id, employee_id, date, checkin, checkout]\n",
      "Index: []\n",
      "All good, there is no missing value for both checkin and checkout.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "missing_both = timesheets[timesheets['checkin'].isnull() & timesheets['checkout'].isnull()]\n",
    "\n",
    "# Display the result\n",
    "print(missing_both)\n",
    "\n",
    "# Answer: Check for missing values in both columns\n",
    "if not missing_both.empty:\n",
    "    print(\"There are rows with missing values in both checkin and checkout.\")\n",
    "else:\n",
    "    print(\"All good, there is no missing value for both checkin and checkout.\")\n",
    "\n",
    "# all good, there is no missing for both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100aa82-fabb-4a56-ac19-5f3c02810704",
   "metadata": {},
   "source": [
    "## Employees Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf3e05-d33e-42b9-b7a2-0ebbb64841b6",
   "metadata": {},
   "source": [
    "- check is there any duplicate for employees table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54e344af-8fc1-4652-ae90-5e1b3fab7023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unique_total_employee  raw_total_employee\n",
      "0                    176                 177\n",
      "There is duplicate data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "employees = pd.read_sql_table(\"employees_python\", con=engine)\n",
    "\n",
    "# Count the total number of employee_id\n",
    "raw_total_employee = employees['employee_id'].count()\n",
    "\n",
    "# Count the number of unique employee_id\n",
    "unique_total_employee = employees['employee_id'].nunique()\n",
    "\n",
    "# Display the results\n",
    "result = pd.DataFrame({\n",
    "    'unique_total_employee': [unique_total_employee],\n",
    "    'raw_total_employee': [raw_total_employee]\n",
    "})\n",
    "\n",
    "print(result)\n",
    "\n",
    "# Answer: Check for duplicates\n",
    "if raw_total_employee > unique_total_employee:\n",
    "    print(\"There is duplicate data.\")\n",
    "else:\n",
    "    print(\"There are no duplicates in the data.\")\n",
    "\n",
    "\n",
    "# there is duplicate data, noted don't run the first code twice, because "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70349007-be67-449f-a036-598cede45862",
   "metadata": {},
   "source": [
    "# salary_per_hour_calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa9124-deff-488d-bb34-5274353c0b34",
   "metadata": {},
   "source": [
    "steps:\n",
    "- remove duplicate on employees table\n",
    "- create new column for fill missing value from checkin and checkout, \n",
    "    assumption:\n",
    "      - There is two shifts\n",
    "      - Indonesia salary rates\n",
    "      - Working day per month is 22\n",
    "- create prorated calculation, since in the data itself, many of employee have not complete working day / month base on their join_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cc8da9e-c0eb-402a-bfe9-61a7f861305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def salary_per_hour_calculation():\n",
    "    ### employees ###\n",
    "    \n",
    "    # employees = pd.read_csv('data/employees.csv')\n",
    "    employees = pd.read_sql_table(\"employees_python\", con=engine)\n",
    "    # rename employe_id to employee_id\n",
    "    employees.rename(columns={'employe_id': 'employee_id'}, inplace=True)\n",
    "    \n",
    "    # Calculate row number based on employee_id, ordered by join_date and salary\n",
    "    employees['row_num'] = employees.sort_values(['join_date', 'salary'], ascending=[False, False]) \\\n",
    "                      .groupby('employee_id') \\\n",
    "                      .cumcount() + 1\n",
    "    \n",
    "    # Select relevant columns\n",
    "    employees_remove_duplicates = employees[['employee_id', 'branch_id', 'salary', 'join_date', 'resign_date', 'row_num']]\n",
    "    \n",
    "    # Filter for rows where row_num is 1\n",
    "    clean_employees = employees_remove_duplicates[employees_remove_duplicates['row_num'] == 1][['employee_id', 'branch_id', 'salary', 'join_date', 'resign_date']]\n",
    "\n",
    "    ### timesheets ###\n",
    "    \n",
    "    # timesheets = pd.read_csv('data/timesheets.csv')\n",
    "    timesheets = pd.read_sql_table(\"timesheets_python\", con=engine)\n",
    "    \n",
    "    # Define a function to apply the CASE logic for checkin_new\n",
    "    def get_checkin_new(row):\n",
    "        if pd.isnull(row['checkin']):\n",
    "            if pd.to_datetime(row['checkout']).time() > pd.to_datetime('12:00:00').time() and pd.to_datetime(row['checkout']).time() < pd.to_datetime('00:00:00').time():\n",
    "                return '08:00:00'\n",
    "            elif pd.to_datetime(row['checkout']).time() > pd.to_datetime('00:00:00').time() and pd.to_datetime(row['checkout']).time() < pd.to_datetime('12:00:00').time():\n",
    "                return '17:00:00'\n",
    "        return row['checkin']\n",
    "    \n",
    "    # Define a function to apply the CASE logic for checkout_new\n",
    "    def get_checkout_new(row):\n",
    "        if pd.isnull(row['checkout']):\n",
    "            if pd.to_datetime(row['checkin']).time() > pd.to_datetime('00:00:00').time() and pd.to_datetime(row['checkin']).time() < pd.to_datetime('12:00:00').time():\n",
    "                return '17:00:00'\n",
    "            elif pd.to_datetime(row['checkin']).time() > pd.to_datetime('12:00:00').time() and pd.to_datetime(row['checkin']).time() < pd.to_datetime('00:00:00').time():\n",
    "                return '08:00:00'\n",
    "        return row['checkout']\n",
    "    \n",
    "    # Apply the functions to create new columns\n",
    "    timesheets['checkin_new'] = timesheets.apply(get_checkin_new, axis=1)\n",
    "    timesheets['checkout_new'] = timesheets.apply(get_checkout_new, axis=1)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    timesheets_modify = timesheets[['timesheet_id', 'employee_id', 'date', 'checkin', 'checkout', 'checkin_new', 'checkout_new']]\n",
    "    \n",
    "    def calculate_total_hours(row):\n",
    "        # Handle NaN values\n",
    "        checkin_new = pd.to_datetime(row['checkin_new'], format='%H:%M:%S', errors='coerce')\n",
    "        checkout_new = pd.to_datetime(row['checkout_new'], format='%H:%M:%S', errors='coerce')\n",
    "        \n",
    "        # If either checkin_new or checkout_new is NaT, return 9.0\n",
    "        if pd.isnull(checkin_new) or pd.isnull(checkout_new):\n",
    "            return 9.0\n",
    "    \n",
    "        # Convert times to seconds for easier calculations\n",
    "        checkin_seconds = (checkin_new.hour * 3600) + (checkin_new.minute * 60) + checkin_new.second\n",
    "        checkout_seconds = (checkout_new.hour * 3600) + (checkout_new.minute * 60) + checkout_new.second\n",
    "    \n",
    "        # Calculate total hours based on conditions\n",
    "        if checkin_seconds > 0 and checkin_seconds < (12 * 3600):\n",
    "            return (checkout_seconds - checkin_seconds) / 3600.0\n",
    "        elif checkin_seconds >= (12 * 3600) and checkin_seconds < (24 * 3600):\n",
    "            return (checkin_seconds - checkout_seconds) / 3600.0\n",
    "        elif checkout_seconds > (12 * 3600) and checkout_seconds < (24 * 3600):\n",
    "            return (checkout_seconds - checkin_seconds) / 3600.0\n",
    "        elif checkout_seconds > 0 and checkout_seconds < (12 * 3600):\n",
    "            return (checkin_seconds - checkout_seconds) / 3600.0\n",
    "        else:\n",
    "            return 9.0\n",
    "    \n",
    "    # Apply the function to create the total_hours column\n",
    "    timesheets_modify['total_hours'] = timesheets_modify.apply(calculate_total_hours, axis=1)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    timesheets_duration = timesheets_modify[['timesheet_id', 'employee_id', 'date', 'checkin', 'checkout', 'checkin_new', 'checkout_new', 'total_hours']]\n",
    "\n",
    "\n",
    "    ### join ###\n",
    "\n",
    "    # Step 1: Perform the left join\n",
    "    merged_df = pd.merge(timesheets_duration, clean_employees, on='employee_id', how='left')\n",
    "    \n",
    "    # Step 2: Filter where salary is not null or not equal to zero\n",
    "    filtered_df = merged_df[(merged_df['salary'].notnull()) & (merged_df['salary'] != 0)]\n",
    "    \n",
    "    filtered_df['date'] = pd.to_datetime(filtered_df['date'])\n",
    "    # Step 3: Extract year and month from the date\n",
    "    filtered_df['year'] = filtered_df['date'].dt.year\n",
    "    filtered_df['month'] = filtered_df['date'].dt.month\n",
    "    \n",
    "    # Step 4: Group by employee_id, branch_id, year, and month\n",
    "    gross_total_hours = (filtered_df.groupby(['employee_id', 'branch_id', 'year', 'month'])\n",
    "                  .agg(total_day=('employee_id', 'count'),\n",
    "                       total_hours=('total_hours', 'sum'),\n",
    "                       salary=('salary', 'min'))\n",
    "                  .reset_index())\n",
    "    \n",
    "    gross_total_hours['prorated_salary'] = gross_total_hours.apply(lambda row: row['salary'] if row['total_day'] > 22 else round((row['total_day'] / 22.0), 2) * row['salary'], axis=1)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    prorated_salary = gross_total_hours[['total_day', 'employee_id', 'branch_id', 'total_hours', 'salary', 'year', 'month', 'prorated_salary']]\n",
    "    \n",
    "    # Calculate salary per hour\n",
    "    prorated_salary['salary_per_hour'] = prorated_salary['prorated_salary'] / prorated_salary['total_hours']\n",
    "    \n",
    "    # Select relevant columns\n",
    "    salary_per_hour = prorated_salary[['total_day', 'employee_id', 'branch_id', 'total_hours', 'salary', 'year', 'month', 'salary_per_hour']]\n",
    "    \n",
    "    # Step 1: Group by branch_id, year, and month\n",
    "    # Step 2: Calculate average salary_per_hour\n",
    "    branch_salary_per_hour = salary_per_hour.groupby(['branch_id', 'year', 'month'], as_index=False)['salary_per_hour'].mean()\n",
    "    \n",
    "    return branch_salary_per_hour\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f14af49-12e9-4674-8bc9-65e631bfdcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/1172092914.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prorated_salary['salary_per_hour'] = prorated_salary['prorated_salary'] / prorated_salary['total_hours']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>salary_per_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>239.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>2.390000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2868.891213</td>\n",
       "      <td>2019.736402</td>\n",
       "      <td>7.523013</td>\n",
       "      <td>1.896986e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2999.106036</td>\n",
       "      <td>0.441509</td>\n",
       "      <td>3.512058</td>\n",
       "      <td>3.038951e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.231133e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2590.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>-3.837916e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2629.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.092579e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2633.500000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>1.753465e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12722.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.684466e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          branch_id         year       month  salary_per_hour\n",
       "count    239.000000   239.000000  239.000000     2.390000e+02\n",
       "mean    2868.891213  2019.736402    7.523013     1.896986e+05\n",
       "std     2999.106036     0.441509    3.512058     3.038951e+06\n",
       "min        1.000000  2019.000000    1.000000    -2.231133e+07\n",
       "25%     2590.000000  2019.000000    4.500000    -3.837916e+04\n",
       "50%     2629.000000  2020.000000    9.000000     5.092579e+04\n",
       "75%     2633.500000  2020.000000   10.500000     1.753465e+05\n",
       "max    12722.000000  2020.000000   12.000000     3.684466e+07"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = salary_per_hour_calculation()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58009aa8-b8e1-4148-8b4c-6413ef0dbc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>salary_per_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>55178.299946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>49162.377224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>50028.529886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>48132.151362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>46341.928185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   branch_id  year  month  salary_per_hour\n",
       "0          1  2019      8     55178.299946\n",
       "1          1  2019      9     49162.377224\n",
       "2          1  2019     10     50028.529886\n",
       "3          1  2019     11     48132.151362\n",
       "4          1  2019     12     46341.928185"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b3a53-ba9a-4b34-a900-b5ec78ed0e9a",
   "metadata": {},
   "source": [
    "# Save transform result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba23f3b1-81d9-4a04-a9f2-818c979f02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory = 'data/transform/python'\n",
    "file_name = 'salary_per_hours.csv'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save the DataFrame to a CSV file in the directory\n",
    "csv_file_path = os.path.join(directory, file_name)\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb3230-3319-422d-b8b7-fbd59d009357",
   "metadata": {},
   "source": [
    "# Load to final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8197b389-510e-4c40-8032-5dacfa51bbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'salary_per_hours_python' does not exist. Creating it now and uploading the data...\n",
      "Table 'salary_per_hours_python' created and data uploaded.\n",
      "Total incremental updates (first run): 239 records inserted.\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'data/transform/python/salary_per_hours.csv'  # Change the path as needed\n",
    "table_name = 'salary_per_hours_python'\n",
    "update_keys = ['branch_id','year','month']\n",
    "incremental_update(engine, csv_file_path, table_name, update_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55cfe7ed-ce02-46a3-9e78-9bfe6f106416",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_sql('SELECT year, month, branch_id, salary_per_hour FROM salary_per_hours_python',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6051c817-cee0-49f7-bb89-43e93e711f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>salary_per_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>239.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>2.390000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019.736402</td>\n",
       "      <td>7.523013</td>\n",
       "      <td>2868.891213</td>\n",
       "      <td>1.896986e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.441509</td>\n",
       "      <td>3.512058</td>\n",
       "      <td>2999.106036</td>\n",
       "      <td>3.038951e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.231133e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2590.000000</td>\n",
       "      <td>-3.837916e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2629.000000</td>\n",
       "      <td>5.092579e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>2633.500000</td>\n",
       "      <td>1.753465e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12722.000000</td>\n",
       "      <td>3.684466e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year       month     branch_id  salary_per_hour\n",
       "count   239.000000  239.000000    239.000000     2.390000e+02\n",
       "mean   2019.736402    7.523013   2868.891213     1.896986e+05\n",
       "std       0.441509    3.512058   2999.106036     3.038951e+06\n",
       "min    2019.000000    1.000000      1.000000    -2.231133e+07\n",
       "25%    2019.000000    4.500000   2590.000000    -3.837916e+04\n",
       "50%    2020.000000    9.000000   2629.000000     5.092579e+04\n",
       "75%    2020.000000   10.500000   2633.500000     1.753465e+05\n",
       "max    2020.000000   12.000000  12722.000000     3.684466e+07"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5213135e-305f-4968-9465-2ac4d5901d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>salary_per_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55178.299946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>49162.377224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>50028.529886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>48132.151362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>46341.928185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  branch_id  salary_per_hour\n",
       "0  2019      8          1     55178.299946\n",
       "1  2019      9          1     49162.377224\n",
       "2  2019     10          1     50028.529886\n",
       "3  2019     11          1     48132.151362\n",
       "4  2019     12          1     46341.928185"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
